{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0c80d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from multiprocessing import Process\n",
    "import gc\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.server.strategy import FedAvg\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from flwr.common.logger import log\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a4484bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input folder\n",
    "#inputFolders = \"../02-transformed-data-new-testes/dados2019/\"\n",
    "inputFolderPath = \"../data_2019_processed/\"\n",
    "\n",
    "# General configuration\n",
    "NUMBER_OF_ITERATIONS = 200\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 0\n",
    "\n",
    "# output folder\n",
    "outputFolder = \"result_unbalanced_epoch_\"+str(NUM_EPOCHS)+\"_rounds_\"+str(NUMBER_OF_ITERATIONS)\n",
    "\n",
    "# train file name modifier\n",
    "fileSufixTrain = \"\" # _smote for smote\n",
    "\n",
    "fl.common.logger.configure(identifier=\"myFlowerExperiment\", filename=\"log\"+outputFolder+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0929b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether the folder exists or not\n",
      "The directory exists!\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking whether the folder exists or not\")\n",
    "isExist = os.path.exists(outputFolder)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(outputFolder)\n",
    "    print(\"The new directory is created!\")\n",
    "else:\n",
    "    print(\"The directory exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75b3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\"light\",\"phone_lock\",\"proximity\",\"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7fa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client datasets used on the training process (75% of data)\n",
    "trainFolders =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                #'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                #'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4']\n",
    "                #'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                #'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                #'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                #'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                #'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                #'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "            \n",
    "# client datasets used on the training process (25% of data)\n",
    "testFolders =  [#'0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                #'0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                #'2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                #'2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                #'7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                #'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                #'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                #'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                #'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                #'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                #'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                #'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                #'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                #'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                #'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                #'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                #'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                #'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                #'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "                'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a8bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    # confusion matrix\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    #print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = (\"[[ \" +str(matrix[0][0]) + \" \" +str(matrix[0][1]) +\"][ \" +str(matrix[1][0]) + \" \" + str(matrix[1][1]) +\"]]\") # array.append(np.array(matrix,dtype=object))\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(\"[[ \" +str(matrix[0][0]) + \" \" +str(matrix[0][1]) +\"][ \" +str(matrix[1][0]) + \" \" + str(matrix[1][1]) +\"]]\") # array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # generate metrics\n",
    "    results, array= generateMetrics(y_test,yhat_probs)\n",
    "\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = results['accuracy']\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = results['precision']\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = results['recall'] \n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = results['f1_score']\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = results['cohen_kappa_score']\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = results['roc_auc_score']\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = results['matrix']\n",
    "    print(matrix)\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def generateGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    res = generateGlobalMetrics(metrics)\n",
    "    \n",
    "    accuracy = res[0]\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1_score = res[3]\n",
    "    cohen_kappa_score = res[4]\n",
    "    roc_auc_score = res[5]\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0789f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the list of directories and concat them\n",
    "def loadDataFromFolders(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        if(i == 0):\n",
    "            temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        else:\n",
    "            dataset = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "            temp_data = pd.concat([temp_data, dataset])\n",
    "    # return the dataset        \n",
    "    return temp_data\n",
    "\n",
    "# take the list of directories and concat them\n",
    "def loadDataFromFoldersOnList(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    clientList = []\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        print(\"Adding to the list: \", temp_data.shape)\n",
    "        clientList.append(temp_data)\n",
    "    # return the dataset        \n",
    "    return clientList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0170ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data\n",
      "8 datasets\n",
      "0 - rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw ../data_2019_processed/student_rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw_transformed.csv\n",
      "1 - RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI ../data_2019_processed/student_RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI_transformed.csv\n",
      "2 - VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is ../data_2019_processed/student_VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is_transformed.csv\n",
      "3 - Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw ../data_2019_processed/student_Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw_transformed.csv\n",
      "4 - XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA ../data_2019_processed/student_XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA_transformed.csv\n",
      "5 - YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw ../data_2019_processed/student_YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw_transformed.csv\n",
      "6 - ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM ../data_2019_processed/student_ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM_transformed.csv\n",
      "7 - ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY ../data_2019_processed/student_ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY_transformed.csv\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>sound</th>\n",
       "      <th>proximity</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>light</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678249</td>\n",
       "      <td>2018-05-14 16:16:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.211282e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678944</td>\n",
       "      <td>2018-05-14 16:17:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679639</td>\n",
       "      <td>2018-05-14 16:18:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680334</td>\n",
       "      <td>2018-05-14 16:19:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681028</td>\n",
       "      <td>2018-05-14 16:20:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819100e-03</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23751</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity  location     timestamp  time_to_next_alarm     sound  \\\n",
       "0          0.75       1.0  0.000000e+00            0.000000  0.515992   \n",
       "1          0.25       1.0  3.211282e-07            0.000000  0.542171   \n",
       "2          0.25       1.0  6.422564e-07            0.000000  0.515992   \n",
       "3          0.00       1.0  6.422564e-07            0.000000  0.515992   \n",
       "4          0.25       1.0  6.422564e-07            0.000000  0.531341   \n",
       "...         ...       ...           ...                 ...       ...   \n",
       "23747      0.25       1.0  5.819100e-03            0.000099  0.000000   \n",
       "23748      0.25       1.0  5.819743e-03            0.000694  0.000000   \n",
       "23749      0.25       1.0  5.819743e-03            0.000595  0.000000   \n",
       "23750      0.25       1.0  5.820064e-03            0.000595  0.000000   \n",
       "23751      0.50       1.0  5.820064e-03            0.000496  0.000000   \n",
       "\n",
       "       proximity  phone_lock     light  day_of_week  minutes_day  \\\n",
       "0            1.0         0.0  0.000000     1.000000     0.678249   \n",
       "1            0.0         1.0  0.000007     1.000000     0.678944   \n",
       "2            0.0         1.0  0.000000     1.000000     0.679639   \n",
       "3            0.0         1.0  0.000000     1.000000     0.680334   \n",
       "4            0.0         1.0  0.000000     1.000000     0.681028   \n",
       "...          ...         ...       ...          ...          ...   \n",
       "23747        1.0         1.0  0.000236     0.166667     0.510076   \n",
       "23748        1.0         1.0  0.000325     0.166667     0.512856   \n",
       "23749        1.0         1.0  0.000325     0.166667     0.513551   \n",
       "23750        1.0         1.0  0.000354     0.166667     0.513551   \n",
       "23751        0.0         1.0  0.000000     0.166667     0.514246   \n",
       "\n",
       "                  timestamp_text  class  \n",
       "0      2018-05-14 16:16:08+00:00  awake  \n",
       "1      2018-05-14 16:17:39+00:00  awake  \n",
       "2      2018-05-14 16:18:39+00:00  awake  \n",
       "3      2018-05-14 16:19:09+00:00  awake  \n",
       "4      2018-05-14 16:20:09+00:00  awake  \n",
       "...                          ...    ...  \n",
       "23747  2018-06-13 12:14:37+00:00  awake  \n",
       "23748  2018-06-13 12:18:08+00:00  awake  \n",
       "23749  2018-06-13 12:19:08+00:00  awake  \n",
       "23750  2018-06-13 12:19:38+00:00  awake  \n",
       "23751  2018-06-13 12:20:08+00:00  awake  \n",
       "\n",
       "[134888 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing test data\")\n",
    " \n",
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "#X_test  = pd.read_csv(inputFolders+\"test/allData-classification-numeric-normalized.csv\")\n",
    "X_test = loadDataFromFolders(testFolders,inputFolderPath,\"\")\n",
    "\n",
    "print()\n",
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bed070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing X_train data\n",
      "19 datasets\n",
      "0 - 0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_transformed.csv\n",
      "Adding to the list:  (17993, 12)\n",
      "1 - 0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_transformed.csv\n",
      "Adding to the list:  (11561, 12)\n",
      "2 - 2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0 ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_transformed.csv\n",
      "Adding to the list:  (3383, 12)\n",
      "3 - 2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_transformed.csv\n",
      "Adding to the list:  (19389, 12)\n",
      "4 - 7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_transformed.csv\n",
      "Adding to the list:  (2753, 12)\n",
      "5 - a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4 ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_transformed.csv\n",
      "Adding to the list:  (26567, 12)\n",
      "6 - ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_transformed.csv\n",
      "Adding to the list:  (24534, 12)\n",
      "7 - Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_transformed.csv\n",
      "Adding to the list:  (33903, 12)\n",
      "8 - CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_transformed.csv\n",
      "Adding to the list:  (26440, 12)\n",
      "9 - DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_transformed.csv\n",
      "Adding to the list:  (24484, 12)\n",
      "10 - dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_transformed.csv\n",
      "Adding to the list:  (26020, 12)\n",
      "11 - HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_transformed.csv\n",
      "Adding to the list:  (25932, 12)\n",
      "12 - jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_transformed.csv\n",
      "Adding to the list:  (31873, 12)\n",
      "13 - JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_transformed.csv\n",
      "Adding to the list:  (23244, 12)\n",
      "14 - K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8 ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_transformed.csv\n",
      "Adding to the list:  (19595, 12)\n",
      "15 - oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_transformed.csv\n",
      "Adding to the list:  (21669, 12)\n",
      "16 - pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_transformed.csv\n",
      "Adding to the list:  (33344, 12)\n",
      "17 - QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_transformed.csv\n",
      "Adding to the list:  (22059, 12)\n",
      "18 - SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4 ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_transformed.csv\n",
      "Adding to the list:  (12709, 12)\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing X_train data\")\n",
    "# load cliend data\n",
    "clientList = loadDataFromFoldersOnList(trainFolders,inputFolderPath,fileSufixTrain)\n",
    "        \n",
    "NUMBER_OF_CLIENTS = len(clientList)\n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c86ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  uint8  \n",
      " 13  asleep              134888 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_nominal_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])\n",
    "    \n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39a58ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float32\n",
      " 1   location            134888 non-null  float32\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float32\n",
      " 4   sound               134888 non-null  float32\n",
      " 5   proximity           134888 non-null  float32\n",
      " 6   phone_lock          134888 non-null  float32\n",
      " 7   light               134888 non-null  float32\n",
      " 8   day_of_week         134888 non-null  float32\n",
      " 9   minutes_day         134888 non-null  float32\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  float32\n",
      " 13  asleep              134888 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec93564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepering the test dataset\n",
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 16:36:45.322843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:45.416303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:45.416769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:45.418539: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 16:36:45.423819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:45.424368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:45.425606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:47.374058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:47.374484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:47.374504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-29 16:36:47.374930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-29 16:36:47.375097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3421 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prepering the test dataset\")\n",
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "#client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "#print(client_test_dataset.element_spec)\n",
    "#client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da70f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing the training datasets\n"
     ]
    }
   ],
   "source": [
    "#print(\"preparing the training datasets\")\n",
    "#federated_training_data = []\n",
    "# transform the data\n",
    "#for i in range(0,len(clientList)):\n",
    "#    # selects the data to train and test\n",
    "#    data   = clientList[i][inputFeatures]\n",
    "#    labels = clientList[i][outputClasses]\n",
    "#    # transform the data to tensor slices\n",
    "#    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "#    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    " #   federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9b73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314\n",
      "Trainable params: 314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"creating model\")\n",
    "\n",
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(16, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35447b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and data (MobileNetV2, CIFAR-10)\n",
    "#model = keras_model\n",
    "#model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362b0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_results(keras_model,X_test_data, y_test_label, current_round_index, \n",
    "                              clientId, prefix_string = \"Results\", lossValue = -1):\n",
    "     # predict values\n",
    "    yhat_probs = keras_model.predict(X_test_data,verbose=VERBOSE)\n",
    "    \n",
    "    # as we deal with a classification problem with one hot encoding, we must round the values to 0 and 1.\n",
    "    yhat_probs_rounded = yhat_probs.round()\n",
    "    \n",
    "    # create a dataframe with the predicted data\n",
    "    y_predicted_df = pd.DataFrame(data=yhat_probs_rounded,columns=['awake','asleep']) \n",
    "    #y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "    \n",
    "    roundData = []\n",
    "\n",
    "    columns = ['client','round','loss','class','accuracy','precision','recall', \n",
    "               'f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "               'TP','FP','FN','TN']\n",
    "    \n",
    "    # Instantiate the list that will contain the results\n",
    "    listOfMetrics = list()\n",
    "    \n",
    "    #print('awake')    \n",
    "    #res,resA = printMetrics(y_test_label['awake'],y_predicted_df['awake'])\n",
    "    res,resA = generateMetrics(y_test_label['awake'],y_predicted_df['awake'])\n",
    "    listOfMetrics.append(res)\n",
    "    \n",
    "    classData = np.concatenate(([clientId,current_round_index,lossValue,'awake'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    #print('')\n",
    "    #print('asleep')\n",
    "    #res,resA = printMetrics(y_test_label['asleep'],y_predicted_df['asleep'])\n",
    "    res,resA = generateMetrics(y_test_label['asleep'],y_predicted_df['asleep'])\n",
    "    listOfMetrics.append(res)\n",
    "    # new data\n",
    "    classData = np.concatenate(([clientId,current_round_index,lossValue,'asleep'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    #print('Global')\n",
    "    #resA = showGlobalMetrics(listOfMetrics) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    resA = generateGlobalMetrics(listOfMetrics) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    # new data\n",
    "    classData = np.concatenate(([clientId,current_round_index,lossValue,'avg'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    dataMetrics = pd.DataFrame(data=roundData,columns=columns) \n",
    "    # write file\n",
    "    if(clientId >= 0):\n",
    "        outputMetricFile = outputFolder+\"/\"+prefix_string+\"_MLP_client_\" + str(clientId) + \"_round_\" + str(current_round_index) + \".csv\"\n",
    "    else:\n",
    "        outputMetricFile = outputFolder+\"/global_model_MLP_metrics.csv\"\n",
    "        # print global model results\n",
    "        if(os.path.isfile(outputMetricFile)):\n",
    "            dataset = pd.read_csv(outputMetricFile)\n",
    "            dataMetrics = pd.concat([dataset, dataMetrics], axis=0)\n",
    "        # Perform garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "    dataMetrics.to_csv(outputMetricFile, sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dca29d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating server function\n"
     ]
    }
   ],
   "source": [
    "print(\"Declarating server function\")\n",
    "# based on: https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems/\n",
    "def start_server(num_rounds: int, num_clients: int):\n",
    "    \"\"\"Start the server with FedAvg strategy.\"\"\"\n",
    "    print(\"Starting server with FedAvg to \"+str(num_clients)+\" for \"+str(num_rounds)+\" rounds\")\n",
    "    strategy = FedAvg(min_available_clients=num_clients)\n",
    "    # Exposes the server by default on port 8080\n",
    "    fl.server.start_server(\n",
    "        server_address=\"0.0.0.0:8099\",\n",
    "        strategy=strategy, \n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71c6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating client function\n"
     ]
    }
   ],
   "source": [
    "print(\"Declarating client function\")\n",
    "\n",
    "# Define a Flower client\n",
    "class FlowerISABELASleepClient(fl.client.NumPyClient):\n",
    "\n",
    "    def __init__(self, clientId, model, X_train_data, y_train_label,round_index=0):\n",
    "        self.round_index = round_index\n",
    "        self.clientId = clientId\n",
    "        self.model = model\n",
    "        self.X_train_data = X_train_data\n",
    "        self.y_train_label = y_train_label\n",
    "\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return current weights.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Fit model and return new weights as well as number of training examples.\"\"\"\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.X_train_data, self.y_train_label, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,verbose=VERBOSE)\n",
    "\n",
    "        # Evaluate local model parameters on the local test data\n",
    "        loss, accuracy = self.model.evaluate(X_test_data, y_test_label,verbose=VERBOSE)\n",
    "\n",
    "        # print model results\n",
    "        evaluate_and_save_results(self.model,X_test_data, y_test_label, self.round_index, self.clientId,\"local_model_results\",loss)\n",
    "        return self.model.get_weights(), len(self.X_train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate using provided parameters.\"\"\"\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "        # Evaluate global model parameters on the local test data\n",
    "        loss, accuracy = self.model.evaluate(X_test_data, y_test_label,verbose=VERBOSE)\n",
    "\n",
    "        print(\"test metrics Accuracy: \"+str(accuracy)+\" - Loss: \"+str(loss))\n",
    "    \n",
    "        # only the Client 0 does it\n",
    "        if(self.clientId == 0):\n",
    "            evaluate_and_save_results(self.model,X_test_data, y_test_label, self.round_index, -1 ,\"global_model\",loss)\n",
    "\n",
    "        # Return results, including the custom accuracy metric\n",
    "        num_examples_test = len(X_test_data)\n",
    "        return loss, num_examples_test, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6e8c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-29 17:02:24,849 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-09-29 17:02:29,846\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2023-09-29 17:02:32,237 | app.py:210 | Flower VCE: Ray initialized with resources: {'node:172.30.126.159': 1.0, 'node:__internal_head__': 1.0, 'memory': 4081392846.0, 'object_store_memory': 2040696422.0, 'CPU': 16.0}\n",
      "INFO flwr 2023-09-29 17:02:32,238 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1}\n",
      "INFO flwr 2023-09-29 17:02:32,260 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 16 actors\n",
      "INFO flwr 2023-09-29 17:02:32,262 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2023-09-29 17:02:32,264 | server.py:276 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1 round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-29 17:02:44,221 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2023-09-29 17:02:44,229 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2023-09-29 17:02:44,232 | server.py:104 | FL starting\n",
      "DEBUG flwr 2023-09-29 17:02:44,238 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 0 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 0 round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m   _warn_prf(average, modifier, msg_start, len(result))\n",
      "DEBUG flwr 2023-09-29 17:02:55,499 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flwr 2023-09-29 17:02:55,514 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-09-29 17:02:55,517 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m 2\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1 round 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1 round 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m test metrics Accuracy: 0.813660204410553 - Loss: 0.4718545973300934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m   _warn_prf(average, modifier, msg_start, len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 0 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 0 round 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Round: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2023-09-29 17:03:04,561 | ray_client_proxy.py:147 | Traceback (most recent call last):\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 140, in _submit_job\n",
      "    res = self.actor_pool.get_client_result(self.cid, timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 402, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 288, in _fetch_future_result\n",
      "    res_cid, res = ray.get(future)  # type: (str, ClientRes)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/worker.py\", line 2524, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientException): \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 0 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "\n",
      "ERROR flwr 2023-09-29 17:03:04,563 | ray_client_proxy.py:148 | \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 0 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "DEBUG flwr 2023-09-29 17:03:04,566 | server.py:187 | evaluate_round 1 received 1 results and 1 failures\n",
      "WARNING flwr 2023-09-29 17:03:04,568 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-09-29 17:03:04,569 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1 round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m test metrics Accuracy: 0.813660204410553 - Loss: 0.4718545973300934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m   _warn_prf(average, modifier, msg_start, len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 0 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0 round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-09-29 17:03:15,003 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-09-29 17:03:15,007 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 0 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0 round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m test metrics Accuracy: 0.813660204410553 - Loss: 0.48220402002334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m /home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m   _warn_prf(average, modifier, msg_start, len(result))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ERROR flwr 2023-09-29 17:03:24,149 | ray_client_proxy.py:147 | Traceback (most recent call last):\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 140, in _submit_job\n",
      "    res = self.actor_pool.get_client_result(self.cid, timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 402, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 288, in _fetch_future_result\n",
      "    res_cid, res = ray.get(future)  # type: (str, ClientRes)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/worker.py\", line 2524, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientException): \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 0 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "\n",
      "ERROR flwr 2023-09-29 17:03:24,151 | ray_client_proxy.py:148 | \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 0 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "ERROR flwr 2023-09-29 17:03:24,305 | ray_client_proxy.py:147 | Traceback (most recent call last):\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 140, in _submit_job\n",
      "    res = self.actor_pool.get_client_result(self.cid, timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 402, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 288, in _fetch_future_result\n",
      "    res_cid, res = ray.get(future)  # type: (str, ClientRes)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/worker.py\", line 2524, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientException): \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 1 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2023-09-29 17:03:24,307 | ray_client_proxy.py:148 | \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27524, ip=172.30.126.159, actor_id=998151bbc80af6b33583e78901000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f30e93603d0>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 1 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "DEBUG flwr 2023-09-29 17:03:24,308 | server.py:187 | evaluate_round 2 received 0 results and 2 failures\n",
      "DEBUG flwr 2023-09-29 17:03:24,309 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1 round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m test metrics Accuracy: 0.813660204410553 - Loss: 0.48220402002334595\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m creating client model to client: 1 round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27524)\u001b[0m 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 0 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 17993\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 0 round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-09-29 17:03:34,908 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
      "DEBUG flwr 2023-09-29 17:03:34,911 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client: 1 <class 'str'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m starting client:  <class 'int'>\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data X: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m Data Y: 11561\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m creating client model to client: 1 round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2023-09-29 17:03:36,740 | ray_client_proxy.py:147 | Traceback (most recent call last):\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 140, in _submit_job\n",
      "    res = self.actor_pool.get_client_result(self.cid, timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 402, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 288, in _fetch_future_result\n",
      "    res_cid, res = ray.get(future)  # type: (str, ClientRes)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/worker.py\", line 2526, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.30.126.159, ID: 2ed659642acd212c0b8ad181684d3060cc48092694c4b9aa15041607) where the task (actor ID: 998151bbc80af6b33583e78901000000, name=DefaultActor.__init__, pid=27524, memory used=0.63GB) was running was 7.07GB / 7.44GB (0.950731), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: d0a93af9b7afb95dd04e6118ee2f1cbf4084539078fb530309323df0) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.30.126.159`. To see the logs of the worker, use `ray logs worker-d0a93af9b7afb95dd04e6118ee2f1cbf4084539078fb530309323df0*out -ip 172.30.126.159. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "20652\t0.99\t/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/bin/python -m ipykernel_launcher -f /home/...\n",
      "27523\t0.67\tray::DefaultActor.run\n",
      "27524\t0.63\tray::DefaultActor\n",
      "27522\t0.25\tray::DefaultActor\n",
      "27504\t0.25\tray::DefaultActor\n",
      "27519\t0.25\tray::DefaultActor\n",
      "27514\t0.25\tray::DefaultActor\n",
      "27506\t0.25\tray::DefaultActor\n",
      "27507\t0.25\tray::DefaultActor\n",
      "27516\t0.25\tray::DefaultActor\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n",
      "ERROR flwr 2023-09-29 17:03:36,742 | ray_client_proxy.py:148 | Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.30.126.159, ID: 2ed659642acd212c0b8ad181684d3060cc48092694c4b9aa15041607) where the task (actor ID: 998151bbc80af6b33583e78901000000, name=DefaultActor.__init__, pid=27524, memory used=0.63GB) was running was 7.07GB / 7.44GB (0.950731), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: d0a93af9b7afb95dd04e6118ee2f1cbf4084539078fb530309323df0) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.30.126.159`. To see the logs of the worker, use `ray logs worker-d0a93af9b7afb95dd04e6118ee2f1cbf4084539078fb530309323df0*out -ip 172.30.126.159. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "20652\t0.99\t/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/bin/python -m ipykernel_launcher -f /home/...\n",
      "27523\t0.67\tray::DefaultActor.run\n",
      "27524\t0.63\tray::DefaultActor\n",
      "27522\t0.25\tray::DefaultActor\n",
      "27504\t0.25\tray::DefaultActor\n",
      "27519\t0.25\tray::DefaultActor\n",
      "27514\t0.25\tray::DefaultActor\n",
      "27506\t0.25\tray::DefaultActor\n",
      "27507\t0.25\tray::DefaultActor\n",
      "27516\t0.25\tray::DefaultActor\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m test metrics Accuracy: 0.7744202613830566 - Loss: 0.5089510083198547\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR flwr 2023-09-29 17:03:44,177 | ray_client_proxy.py:147 | Traceback (most recent call last):\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 140, in _submit_job\n",
      "    res = self.actor_pool.get_client_result(self.cid, timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 402, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 288, in _fetch_future_result\n",
      "    res_cid, res = ray.get(future)  # type: (str, ClientRes)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/ray/_private/worker.py\", line 2524, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientException): \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 1 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "\n",
      "ERROR flwr 2023-09-29 17:03:44,178 | ray_client_proxy.py:148 | \u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\n",
      "    return maybe_call_evaluate(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\n",
      "    return client.evaluate(evaluate_ins)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\n",
      "    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\n",
      "  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\n",
      "  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\n",
      "UnboundLocalError: local variable 'outputMetricFile' referenced before assignment\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::DefaultActor.run()\u001b[39m (pid=27523, ip=172.30.126.159, actor_id=ddfa4171f36278a559b95fbd01000000, repr=<flwr.simulation.ray_transport.ray_actor.DefaultActor object at 0x7f2e1d1c2490>)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 72, in run\n",
      "    raise ClientException(str(message)) from ex\n",
      "flwr.simulation.ray_transport.ray_actor.ClientException: \n",
      ">>>>>>>A ClientException occurred.('\\n\\tSomething went wrong when running your client workload.\\n\\tClient 1 crashed when the DefaultActor was running its workload.\\n\\tException triggered on the client side: Traceback (most recent call last):\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 60, in run\\n    job_results = job_fn()\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 215, in evaluate\\n    return maybe_call_evaluate(\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/client.py\", line 237, in maybe_call_evaluate\\n    return client.evaluate(evaluate_ins)\\n  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py\", line 357, in _evaluate\\n    results = self.numpy_client.evaluate(parameters, ins.config)  # type: ignore\\n  File \"/tmp/ipykernel_20652/810984218.py\", line 39, in evaluate\\n  File \"/tmp/ipykernel_20652/3708332468.py\", line 58, in evaluate_and_save_results\\nUnboundLocalError: local variable \\'outputMetricFile\\' referenced before assignment\\n',)\n",
      "DEBUG flwr 2023-09-29 17:03:44,179 | server.py:187 | evaluate_round 3 received 0 results and 2 failures\n",
      "INFO flwr 2023-09-29 17:03:44,181 | server.py:153 | FL finished in 59.94640599100239\n",
      "INFO flwr 2023-09-29 17:03:44,184 | app.py:225 | app_fit: losses_distributed [(1, 0.4718545973300934)]\n",
      "INFO flwr 2023-09-29 17:03:44,185 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2023-09-29 17:03:44,186 | app.py:227 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2023-09-29 17:03:44,187 | app.py:228 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-09-29 17:03:44,188 | app.py:229 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DefaultActor pid=27523)\u001b[0m 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.4718545973300934"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-09-29 17:04:29,776 E 27072 27072] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 2ed659642acd212c0b8ad181684d3060cc48092694c4b9aa15041607, IP: 172.30.126.159) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.126.159`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import math\n",
    "# Create an instance of the model and get the parameters\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "#if DEVICE.type == \"cuda\":\n",
    "\n",
    "client_resources = {\"num_cpus\": 1}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerISABELASleepClient:\n",
    "    print(\"starting client: \"+str(cid),type(cid))\n",
    "    #convert client ID to int\n",
    "    clientId = int(cid)\n",
    "    print(\"starting client: \", type(clientId))\n",
    "\n",
    "    data   = clientList[clientId][inputFeatures]\n",
    "    labels = clientList[clientId][outputClasses]\n",
    "    \n",
    "    print(\"creating client model to client: \"+str(cid))\n",
    "    print(\"Data X: \"+str(len(data)))\n",
    "    print(\"Data Y: \"+str(len(labels)))\n",
    "    \n",
    "    file_global_model = outputFolder+\"/global_model_MLP_metrics.csv\"\n",
    "    index_round = 0    \n",
    "    # print global model results\n",
    "    if(os.path.isfile(file_global_model)):\n",
    "        dataset = pd.read_csv(file_global_model)\n",
    "        index_round = dataset[\"round\"].max() + 1\n",
    "        del dataset\n",
    "    \n",
    "    print(\"creating client model to client: \"+str(cid),\"round\",index_round)\n",
    "    # Load and compile a Keras model for CIFAR-10\n",
    "    model = create_keras_model()\n",
    "    model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return FlowerISABELASleepClient(clientId,model,data,labels,index_round)\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUMBER_OF_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUMBER_OF_ITERATIONS),  # Just three rounds\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f400a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2c363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc76a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25c20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2d7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
