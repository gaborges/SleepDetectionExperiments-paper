{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e90a0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from multiprocessing import Process\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.server.strategy import FedAvg\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from flwr.common.logger import log\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "\n",
    "# Make TensorFlow log less verbose\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa07ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input folder\n",
    "#inputFolders = \"../02-transformed-data-new-testes/dados2019/\"\n",
    "inputFolderPath = \"../data_2019_processed/\"\n",
    "\n",
    "# General configuration\n",
    "NUMBER_OF_ITERATIONS = 120\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 0\n",
    "\n",
    "# output folder\n",
    "outputFolder = \"result-unbalanced_test\"\n",
    "\n",
    "# train file name modifier\n",
    "fileSufixTrain = \"\" # _smote for smote\n",
    "\n",
    "fl.common.logger.configure(identifier=\"myFlowerExperiment\", filename=\"log\"+outputFolder+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53ff1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\"light\",\"phone_lock\",\"proximity\",\"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1b4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client datasets used on the training process (75% of data)\n",
    "trainFolders =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                #'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                #'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4']\n",
    "                #'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                #'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                #'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                #'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                #'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                #'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "            \n",
    "# client datasets used on the training process (25% of data)\n",
    "testFolders =  [#'0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                #'0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                #'2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                #'2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                #'7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                #'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                #'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                #'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                #'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                #'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                #'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                #'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                #'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                #'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                #'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                #'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                #'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                #'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                #'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "                'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "272114e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    # confusion matrix\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    #print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    results['matrix'] = (\"[[ \" +str(matrix[0][0]) + \" \" +str(matrix[0][1]) +\"][ \" +str(matrix[1][0]) + \" \" + str(matrix[1][1]) +\"]]\") # array.append(np.array(matrix,dtype=object))\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    array.append(\"[[ \" +str(matrix[0][0]) + \" \" +str(matrix[0][1]) +\"][ \" +str(matrix[1][0]) + \" \" + str(matrix[1][1]) +\"]]\") # array.append(np.array(matrix,dtype=object))\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # generate metrics\n",
    "    results, array= generateMetrics(y_test,yhat_probs)\n",
    "\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = results['accuracy']\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = results['precision']\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = results['recall'] \n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = results['f1_score']\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = results['cohen_kappa_score']\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = results['roc_auc_score']\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = results['matrix']\n",
    "    print(matrix)\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def generateGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    res = generateGlobalMetrics(metrics)\n",
    "    \n",
    "    accuracy = res[0]\n",
    "    precision = res[1]\n",
    "    recall = res[2]\n",
    "    f1_score = res[3]\n",
    "    cohen_kappa_score = res[4]\n",
    "    roc_auc_score = res[5]\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14cd6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the list of directories and concat them\n",
    "def loadDataFromFolders(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        if(i == 0):\n",
    "            temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        else:\n",
    "            dataset = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "            temp_data = pd.concat([temp_data, dataset])\n",
    "    # return the dataset        \n",
    "    return temp_data\n",
    "\n",
    "# take the list of directories and concat them\n",
    "def loadDataFromFoldersOnList(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    clientList = []\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        print(\"Adding to the list: \", temp_data.shape)\n",
    "        clientList.append(temp_data)\n",
    "    # return the dataset        \n",
    "    return clientList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71b44975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data\n",
      "8 datasets\n",
      "0 - rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw ../data_2019_processed/student_rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw_transformed.csv\n",
      "1 - RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI ../data_2019_processed/student_RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI_transformed.csv\n",
      "2 - VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is ../data_2019_processed/student_VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is_transformed.csv\n",
      "3 - Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw ../data_2019_processed/student_Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw_transformed.csv\n",
      "4 - XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA ../data_2019_processed/student_XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA_transformed.csv\n",
      "5 - YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw ../data_2019_processed/student_YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw_transformed.csv\n",
      "6 - ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM ../data_2019_processed/student_ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM_transformed.csv\n",
      "7 - ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY ../data_2019_processed/student_ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY_transformed.csv\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>sound</th>\n",
       "      <th>proximity</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>light</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678249</td>\n",
       "      <td>2018-05-14 16:16:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.211282e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678944</td>\n",
       "      <td>2018-05-14 16:17:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679639</td>\n",
       "      <td>2018-05-14 16:18:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680334</td>\n",
       "      <td>2018-05-14 16:19:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681028</td>\n",
       "      <td>2018-05-14 16:20:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819100e-03</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23751</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity  location     timestamp  time_to_next_alarm     sound  \\\n",
       "0          0.75       1.0  0.000000e+00            0.000000  0.515992   \n",
       "1          0.25       1.0  3.211282e-07            0.000000  0.542171   \n",
       "2          0.25       1.0  6.422564e-07            0.000000  0.515992   \n",
       "3          0.00       1.0  6.422564e-07            0.000000  0.515992   \n",
       "4          0.25       1.0  6.422564e-07            0.000000  0.531341   \n",
       "...         ...       ...           ...                 ...       ...   \n",
       "23747      0.25       1.0  5.819100e-03            0.000099  0.000000   \n",
       "23748      0.25       1.0  5.819743e-03            0.000694  0.000000   \n",
       "23749      0.25       1.0  5.819743e-03            0.000595  0.000000   \n",
       "23750      0.25       1.0  5.820064e-03            0.000595  0.000000   \n",
       "23751      0.50       1.0  5.820064e-03            0.000496  0.000000   \n",
       "\n",
       "       proximity  phone_lock     light  day_of_week  minutes_day  \\\n",
       "0            1.0         0.0  0.000000     1.000000     0.678249   \n",
       "1            0.0         1.0  0.000007     1.000000     0.678944   \n",
       "2            0.0         1.0  0.000000     1.000000     0.679639   \n",
       "3            0.0         1.0  0.000000     1.000000     0.680334   \n",
       "4            0.0         1.0  0.000000     1.000000     0.681028   \n",
       "...          ...         ...       ...          ...          ...   \n",
       "23747        1.0         1.0  0.000236     0.166667     0.510076   \n",
       "23748        1.0         1.0  0.000325     0.166667     0.512856   \n",
       "23749        1.0         1.0  0.000325     0.166667     0.513551   \n",
       "23750        1.0         1.0  0.000354     0.166667     0.513551   \n",
       "23751        0.0         1.0  0.000000     0.166667     0.514246   \n",
       "\n",
       "                  timestamp_text  class  \n",
       "0      2018-05-14 16:16:08+00:00  awake  \n",
       "1      2018-05-14 16:17:39+00:00  awake  \n",
       "2      2018-05-14 16:18:39+00:00  awake  \n",
       "3      2018-05-14 16:19:09+00:00  awake  \n",
       "4      2018-05-14 16:20:09+00:00  awake  \n",
       "...                          ...    ...  \n",
       "23747  2018-06-13 12:14:37+00:00  awake  \n",
       "23748  2018-06-13 12:18:08+00:00  awake  \n",
       "23749  2018-06-13 12:19:08+00:00  awake  \n",
       "23750  2018-06-13 12:19:38+00:00  awake  \n",
       "23751  2018-06-13 12:20:08+00:00  awake  \n",
       "\n",
       "[134888 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing test data\")\n",
    " \n",
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "#X_test  = pd.read_csv(inputFolders+\"test/allData-classification-numeric-normalized.csv\")\n",
    "X_test = loadDataFromFolders(testFolders,inputFolderPath,\"\")\n",
    "\n",
    "print()\n",
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1243c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing X_train data\n",
      "19 datasets\n",
      "0 - 0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_transformed.csv\n",
      "Adding to the list:  (17993, 12)\n",
      "1 - 0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_transformed.csv\n",
      "Adding to the list:  (11561, 12)\n",
      "2 - 2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0 ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_transformed.csv\n",
      "Adding to the list:  (3383, 12)\n",
      "3 - 2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_transformed.csv\n",
      "Adding to the list:  (19389, 12)\n",
      "4 - 7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_transformed.csv\n",
      "Adding to the list:  (2753, 12)\n",
      "5 - a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4 ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_transformed.csv\n",
      "Adding to the list:  (26567, 12)\n",
      "6 - ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_transformed.csv\n",
      "Adding to the list:  (24534, 12)\n",
      "7 - Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_transformed.csv\n",
      "Adding to the list:  (33903, 12)\n",
      "8 - CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_transformed.csv\n",
      "Adding to the list:  (26440, 12)\n",
      "9 - DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_transformed.csv\n",
      "Adding to the list:  (24484, 12)\n",
      "10 - dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_transformed.csv\n",
      "Adding to the list:  (26020, 12)\n",
      "11 - HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_transformed.csv\n",
      "Adding to the list:  (25932, 12)\n",
      "12 - jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_transformed.csv\n",
      "Adding to the list:  (31873, 12)\n",
      "13 - JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_transformed.csv\n",
      "Adding to the list:  (23244, 12)\n",
      "14 - K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8 ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_transformed.csv\n",
      "Adding to the list:  (19595, 12)\n",
      "15 - oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_transformed.csv\n",
      "Adding to the list:  (21669, 12)\n",
      "16 - pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_transformed.csv\n",
      "Adding to the list:  (33344, 12)\n",
      "17 - QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_transformed.csv\n",
      "Adding to the list:  (22059, 12)\n",
      "18 - SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4 ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_transformed.csv\n",
      "Adding to the list:  (12709, 12)\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing X_train data\")\n",
    "# load cliend data\n",
    "clientList = loadDataFromFoldersOnList(trainFolders,inputFolderPath,fileSufixTrain)\n",
    "        \n",
    "NUMBER_OF_CLIENTS = len(clientList)\n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4bb8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  uint8  \n",
      " 13  asleep              134888 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_nominal_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])\n",
    "    \n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1f0f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float32\n",
      " 1   location            134888 non-null  float32\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float32\n",
      " 4   sound               134888 non-null  float32\n",
      " 5   proximity           134888 non-null  float32\n",
      " 6   phone_lock          134888 non-null  float32\n",
      " 7   light               134888 non-null  float32\n",
      " 8   day_of_week         134888 non-null  float32\n",
      " 9   minutes_day         134888 non-null  float32\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  float32\n",
      " 13  asleep              134888 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9411021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepering the test dataset\n",
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prepering the test dataset\")\n",
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc6471fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing the training datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"preparing the training datasets\")\n",
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28e2c26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 16)                160       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314\n",
      "Trainable params: 314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"creating model\")\n",
    "\n",
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(16, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67dda42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and data (MobileNetV2, CIFAR-10)\n",
    "model = keras_model\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1382d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating the function to generate the metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"Declarating the function to generate the metrics\")\n",
    "\n",
    "def evaluate_and_save_results(keras_model,X_test_data, y_test_label, current_round_index, \n",
    "                              clientId, prefix_string = \"Results\", lossValue = -1):\n",
    "     # predict values\n",
    "    yhat_probs = keras_model.predict(X_test_data)\n",
    "    \n",
    "    # as we deal with a classification problem with one hot encoding, we must round the values to 0 and 1.\n",
    "    yhat_probs_rounded = yhat_probs.round()\n",
    "    \n",
    "    # create a dataframe with the predicted data\n",
    "    y_predicted_df = pd.DataFrame(data=yhat_probs_rounded,columns=['awake','asleep']) \n",
    "    #y_test_label_label = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "    \n",
    "    roundData = []\n",
    "\n",
    "    columns = ['client','round','loss','class','accuracy','precision','recall', \n",
    "               'f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "               'TP','FP','FN','TN']\n",
    "    \n",
    "    # Instantiate the list that will contain the results\n",
    "    listOfMetrics = list()\n",
    "    \n",
    "    #print('awake')    \n",
    "    #res,resA = printMetrics(y_test_label['awake'],y_predicted_df['awake'])\n",
    "    res,resA = generateMetrics(y_test_label['awake'],y_predicted_df['awake'])\n",
    "    listOfMetrics.append(res)\n",
    "    \n",
    "    classData = np.concatenate(([clientId,lossValue,current_round_index,'awake'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    #print('')\n",
    "    #print('asleep')\n",
    "    #res,resA = printMetrics(y_test_label['asleep'],y_predicted_df['asleep'])\n",
    "    res,resA = generateMetrics(y_test_label['asleep'],y_predicted_df['asleep'])\n",
    "    listOfMetrics.append(res)\n",
    "    # new data\n",
    "    classData = np.concatenate(([clientId,lossValue,current_round_index,'asleep'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    #print('Global')\n",
    "    #resA = showGlobalMetrics(listOfMetrics) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    resA = generateGlobalMetrics(listOfMetrics) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    # new data\n",
    "    classData = np.concatenate(([clientId,lossValue,current_round_index,'avg'], resA))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    dataMetrics = pd.DataFrame(data=roundData,columns=columns) \n",
    "    \n",
    "    # write file\n",
    "    outputMetricFile = outputFolder+\"/\"+prefix_string+\"_MLP_unbalanced_client_\" + str(clientId) + \"_round_\" + str(current_round_index) + \".csv\"\n",
    "    dataMetrics.to_csv(outputMetricFile, sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54eae2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating server function\n"
     ]
    }
   ],
   "source": [
    "print(\"Declarating server function\")\n",
    "# based on: https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems/\n",
    "def start_server(num_rounds: int, num_clients: int):\n",
    "    \"\"\"Start the server with FedAvg strategy.\"\"\"\n",
    "    print(\"Starting server with FedAvg to \"+str(num_clients)+\" for \"+str(num_rounds)+\" rounds\")\n",
    "    strategy = FedAvg(min_available_clients=num_clients)\n",
    "    # Exposes the server by default on port 8080\n",
    "    fl.server.start_server(\n",
    "        server_address=\"0.0.0.0:8099\",\n",
    "        strategy=strategy, \n",
    "        config=fl.server.ServerConfig(num_rounds=num_rounds)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff238d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating client class\n"
     ]
    }
   ],
   "source": [
    "# Define a Flower client\n",
    "print(\"Declarating client class\")\n",
    "\n",
    "class FlowerISABELASleepClient(fl.client.NumPyClient):\n",
    "\n",
    "    def __init__(self, clientId, model, X_train_data, y_train_label):\n",
    "        self.round_index = 0\n",
    "        self.clientId = clientId\n",
    "        self.model = model\n",
    "        self.X_train_data = X_train_data\n",
    "        self.y_train_label = y_train_label\n",
    "\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return current weights.\"\"\"\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Fit model and return new weights as well as number of training examples.\"\"\"\n",
    "        model.set_weights(parameters)\n",
    "        model.fit(X_train_data, y_train_label, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,verbose=VERBOSE)\n",
    "\n",
    "        # Evaluate local model parameters on the local test data\n",
    "        loss, accuracy = model.evaluate(X_test_data, y_test_label,verbose=VERBOSE)\n",
    "\n",
    "        # print model results\n",
    "        evaluate_and_save_results(model,X_test_data, y_test_label, round_index, clientId,\"local_model_results\",loss)\n",
    "        return model.get_weights(), len(X_train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate using provided parameters.\"\"\"\n",
    "        model.set_weights(parameters)\n",
    "\n",
    "        # Evaluate global model parameters on the local test data\n",
    "        loss, accuracy = model.evaluate(X_test_data, y_test_label,verbose=VERBOSE)\n",
    "\n",
    "        print(\"test metrics Accuracy: \"+accuracy+\" - Loss: \"+loss)\n",
    "\n",
    "        file_global_model = outputFolder+\"/global_model_MLP_\"+str(round_index)\n",
    "        # print global model results\n",
    "        if(not(os.path.isfile(file_global_model))):\n",
    "            evaluate_and_save_results(keras_model,X_test_data, y_test_label, round_index, 0 ,\"global_model\",loss)\n",
    "        # increment round\n",
    "        round_index = round_index + 1\n",
    "\n",
    "        # Return results, including the custom accuracy metric\n",
    "        num_examples_test = len(X_test_data)\n",
    "        return loss, num_examples_test, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e153051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarating client function\n"
     ]
    }
   ],
   "source": [
    "print(\"Declarating client function\")\n",
    "\n",
    "def start_client(X_train_data: DataFrame, y_train_label: DataFrame, \n",
    "                 clientId : int\n",
    "                ) -> None:\n",
    "    \"\"\"Start a single client with the provided dataset.\"\"\"\n",
    "\n",
    "    print(\"creating client model\")\n",
    "    # Load and compile a Keras model for CIFAR-10\n",
    "    model = create_keras_model()\n",
    "    model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Start Flower client\n",
    "    fl.client.start_numpy_client(server_address=\"127.0.0.1:8099\", client=FlowerISABELASleepClient(X_train_data,y_train_label, clientId, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77d8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "425b5e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define simulation script\n"
     ]
    }
   ],
   "source": [
    "print(\"Define simulation script\")\n",
    "\n",
    "# based on\n",
    "def run_simulation(num_rounds: int, num_clients: int):\n",
    "    \"\"\"Start a FL simulation.\"\"\"\n",
    "\n",
    "    # This will hold all the processes which we are going to create\n",
    "    processes = []\n",
    "\n",
    "    # Start the server\n",
    "    server_process = Process(target=start_server, args=(num_rounds, num_clients))\n",
    "    server_process.start()\n",
    "    processes.append(server_process)\n",
    "\n",
    "    # Optionally block the script here for a second or two so the server has time to start\n",
    "    time.sleep(3)\n",
    "    \n",
    "    for i in range(0,num_clients):\n",
    "        # selects the data to train and test\n",
    "        data   = clientList[i][inputFeatures]\n",
    "        labels = clientList[i][outputClasses]\n",
    "        \n",
    "        client_process = Process(target=start_client, args=(data,labels,i))\n",
    "        client_process.start()\n",
    "        processes.append(client_process)\n",
    "        \n",
    "    start_client(data,labels,i)\n",
    "    # Block until all processes are finished\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a03da135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start simulation\n",
      "Starting server with FedAvg to 2 for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-29 00:33:48,498 | app.py:162 | Starting Flower server, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
      "INFO flwr 2023-09-29 00:33:48,513 | app.py:175 | Flower ECE: gRPC server running (10 rounds), SSL is disabled\n",
      "INFO flwr 2023-09-29 00:33:48,516 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2023-09-29 00:33:48,517 | server.py:276 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating client model\n",
      "creating client model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 00:33:51.548939: F tensorflow/stream_executor/cuda/cuda_driver.cc:146] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "2023-09-29 00:33:51.578294: F tensorflow/stream_executor/cuda/cuda_driver.cc:146] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "INFO flwr 2023-09-29 00:33:51,616 | grpc.py:49 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-09-29 00:33:51,640 | connection.py:42 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-09-29 00:33:51,645 | connection.py:42 | ChannelConnectivity.CONNECTING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating client model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "DEBUG flwr 2023-09-29 00:34:03,304 | connection.py:139 | gRPC channel closed\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3913/54506671.py\", line 8, in start_server\n",
      "    fl.server.start_server(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#run_simulation(num_rounds=NUMBER_OF_ITERATIONS, num_clients=NUMBER_OF_CLIENTS)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [49], line 27\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(num_rounds, num_clients)\u001b[0m\n\u001b[1;32m     24\u001b[0m     client_process\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     25\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(client_process)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Block until all processes are finished\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes:\n",
      "Cell \u001b[0;32mIn [48], line 17\u001b[0m, in \u001b[0;36mstart_client\u001b[0;34m(X_train_data, y_train_label, clientId)\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Start Flower client\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_numpy_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1:8099\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFlowerISABELASleepClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclientId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py:288\u001b[0m, in \u001b[0;36mstart_numpy_client\u001b[0;34m(server_address, client, grpc_max_message_length, root_certificates, rest, transport)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"Start a Flower NumPyClient which connects to a gRPC server.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m>>> )\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Start\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_wrap_numpy_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/app.py:201\u001b[0m, in \u001b[0;36mstart_client\u001b[0;34m(server_address, client, grpc_max_message_length, root_certificates, rest, transport)\u001b[0m\n\u001b[1;32m    198\u001b[0m     create_node()  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     task_ins \u001b[38;5;241m=\u001b[39m \u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task_ins \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for 3s before asking again\u001b[39;00m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/client/grpc_client/connection.py:116\u001b[0m, in \u001b[0;36mgrpc_connection.<locals>.receive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskIns:\n\u001b[0;32m--> 116\u001b[0m     server_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mserver_message_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TaskIns(\n\u001b[1;32m    118\u001b[0m         task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()),\n\u001b[1;32m    119\u001b[0m         group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         ),\n\u001b[1;32m    127\u001b[0m     )\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/grpc/_channel.py:426\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/grpc/_channel.py:817\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_response_ready\u001b[39m():\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    813\u001b[0m             (cygrpc\u001b[38;5;241m.\u001b[39mOperationType\u001b[38;5;241m.\u001b[39mreceive_message\n\u001b[1;32m    814\u001b[0m              \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdue \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    815\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 817\u001b[0m \u001b[43m_common\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_response_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mresponse\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/grpc/_common.py:150\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_complete_fn():\n\u001b[0;32m--> 150\u001b[0m         \u001b[43m_wait_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXIMUM_WAIT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspin_cb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m timeout\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/grpc/_common.py:112\u001b[0m, in \u001b[0;36m_wait_once\u001b[0;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_once\u001b[39m(wait_fn: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m], timeout: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    111\u001b[0m                spin_cb: Optional[Callable[[], \u001b[38;5;28;01mNone\u001b[39;00m]]):\n\u001b[0;32m--> 112\u001b[0m     \u001b[43mwait_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spin_cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         spin_cb()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/app.py\", line 183, in start_server\n",
      "    hist = run_fl(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/app.py\", line 224, in run_fl\n",
      "    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/server.py\", line 90, in fit\n",
      "    self.parameters = self._get_initial_parameters(timeout=timeout)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/server.py\", line 277, in _get_initial_parameters\n",
      "    random_client = self._client_manager.sample(1)[0]\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/client_manager.py\", line 187, in sample\n",
      "    self.wait_for(min_num_clients)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/flwr/server/client_manager.py\", line 132, in wait_for\n",
      "    return self._cv.wait_for(\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py\", line 347, in wait_for\n",
      "    self.wait(waittime)\n",
      "  File \"/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/threading.py\", line 316, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "print(\"Start simulation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_simulation(num_rounds=NUMBER_OF_ITERATIONS, num_clients=NUMBER_OF_CLIENTS)\n",
    "    #run_simulation(num_rounds=10, num_clients=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
