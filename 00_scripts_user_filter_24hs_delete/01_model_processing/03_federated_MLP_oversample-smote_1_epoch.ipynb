{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc3553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 18:13:25.375324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 18:13:25.540103: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-28 18:13:26.021497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-09-28 18:13:26.023257: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/\n",
      "2023-09-28 18:13:26.023265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "# Bibliotecas Auxiliares\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_federated as tff\n",
    "np.random.seed(0)\n",
    "from collections import Counter\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280fd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test     = Array with real values\n",
    "# yhat_probs = Array with predicted values\n",
    "def printMetrics(y_test,yhat_probs):\n",
    "    # predict crisp classes for test set deprecated\n",
    "    #yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "    #yhat_classes = np.argmax(yhat_probs,axis=1)\n",
    "    yhat_classes = yhat_probs.round()\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y_test, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y_test, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y_test, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y_test, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "    auc = roc_auc_score(y_test, yhat_probs)\n",
    "    print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    print(\"\\Confusion Matrix\")\n",
    "    matrix = confusion_matrix(y_test, yhat_classes)\n",
    "    print(matrix)\n",
    "    \n",
    "    array = []\n",
    "    results = dict()\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1_score'] = f1\n",
    "    results['cohen_kappa_score'] = kappa\n",
    "    results['roc_auc_score'] = auc\n",
    "    #results['matrix'] = np.array(matrix,dtype=object)\n",
    "    results['matrix'] = np.array(0)\n",
    "    results['TP'] = matrix[0][0]\n",
    "    results['FP'] = matrix[0][1]\n",
    "    results['FN'] = matrix[1][0]\n",
    "    results['TN'] = matrix[1][1]\n",
    "    \n",
    "    array.append(accuracy)\n",
    "    array.append(precision)\n",
    "    array.append(recall)\n",
    "    array.append(f1)\n",
    "    array.append(kappa)\n",
    "    array.append(auc)\n",
    "    #array.append(np.array(matrix,dtype=object))\n",
    "    array.append(0)\n",
    "    array.append(matrix[0][0]) # TP\n",
    "    array.append(matrix[0][1]) # FP\n",
    "    array.append(matrix[1][0]) # FN\n",
    "    array.append(matrix[1][1]) # TN\n",
    "    \n",
    "    return results, array\n",
    "\n",
    "def showGlobalMetrics(metrics):\n",
    "    accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score = 0,0,0,0,0,0\n",
    "    for metric in metrics:\n",
    "        accuracy = accuracy + metric['accuracy']\n",
    "        precision = precision + metric['precision']\n",
    "        recall = recall + metric['recall']\n",
    "        f1_score = f1_score + metric['f1_score']\n",
    "        cohen_kappa_score = cohen_kappa_score + metric['cohen_kappa_score']\n",
    "        roc_auc_score = roc_auc_score + metric['roc_auc_score']\n",
    "        \n",
    "    # mean\n",
    "    size = len(metrics)\n",
    "    print(size)\n",
    "    accuracy = accuracy / size\n",
    "    precision = precision / size\n",
    "    recall = recall / size\n",
    "    f1_score = f1_score / size\n",
    "    cohen_kappa_score = cohen_kappa_score / size\n",
    "    roc_auc_score = roc_auc_score / size\n",
    "    \n",
    "    #show:\\\n",
    "    print(\"accuracy: \",accuracy)\n",
    "    print(\"precision: \",precision)\n",
    "    print(\"recall: \",recall)\n",
    "    print(\"f1_score: \",f1_score)\n",
    "    print(\"cohen_kappa_score: \",cohen_kappa_score)\n",
    "    print(\"roc_auc_score: \",roc_auc_score)\n",
    "    \n",
    "    return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score]\n",
    "\n",
    "def create_dataset_time_series_with_one_output_foward(X, y, window_time_steps=1, shift_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - window_time_steps, shift_step):\n",
    "        valuesX = X.iloc[i:(i + window_time_steps)].values # values\n",
    "        valuesY = y.iloc[i: i + window_time_steps].values # labels\n",
    "        \n",
    "        Xs.append(valuesX)\n",
    "        ys.append(valuesY[window_time_steps-1]) # append only the last value\n",
    "        \n",
    "    if len(y.columns) == 1:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "    else:\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, len(y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e68b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "EPOCHS = 1\n",
    "NUM_EPOCHS = EPOCHS\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITERATIONS = 120\n",
    "\n",
    "\n",
    "baseFolder = \"../data_2019_processed/\"\n",
    "\n",
    "fileSufixTrain = \"smote\" \n",
    "\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\n",
    "                 \"light\",\"phone_lock\",\"proximity\",\n",
    "                 \"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "# outputs\n",
    "outputClasses = [\"awake\",\"asleep\"]\n",
    "#outputClasses = [\"class\"]\n",
    "\n",
    "NN_type = 'MPL'\n",
    "UNITS_NUMBER = \"16-8\";\n",
    "EPOCHS_ARRAY_TEST = [5,15,30,50,80,100,120,150,200]\n",
    "\n",
    "TIME_SERIES_SIZE = 4   # Determines the window size. Ex (4,9)\n",
    "TIME_STEP_SHIFT  = 1   # Determines specifies the number of steps to move the window forward at each iteration.\n",
    "TIME_SERIES_SIZE = -1 # we do not use it\n",
    "TIME_STEP_SHIFT = -1 # we do not use it\n",
    "\n",
    "outputMetricFile = \"result_federated_\"+str(NN_type)+\"_\"+fileSufixTrain+\"_batch_size_\"+str(BATCH_SIZE)+\"_max_iteration_\"+str(MAX_ITERATIONS)+\"_epochs_\"+str(EPOCHS)+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4d28cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result_federated_MPL_smote_batch_size_32_max_iteration_120_epochs_1.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputMetricFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "# X_test  = pd.read_csv(baseFolder+\"test/allData-classification-numeric-normalized.csv\")\n",
    "\n",
    "# input folder\n",
    "inputFolders = baseFolder\n",
    "            \n",
    "# client datasets used on the training process (75% of data)\n",
    "trainFolders =  ['0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                '0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                '2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                '2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                '7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                #'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                #'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4']\n",
    "                #'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                #'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                #'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                #'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                #'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                #'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "            \n",
    "# client datasets used on the training process (25% of data)\n",
    "testFolders =  [#'0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                #'0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                #'2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                #'2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                #'7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                #'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                #'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                #'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                #'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                #'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                #'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                #'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                #'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                #'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                #'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                #'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                #'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                #'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                #'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                #'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "                'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "\n",
    "# take the list of directories and concat them\n",
    "def loadDataFromFolders(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        if(i == 0):\n",
    "            temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        else:\n",
    "            dataset = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "            temp_data = pd.concat([temp_data, dataset])\n",
    "    # return the dataset        \n",
    "    return temp_data\n",
    "\n",
    "# take the list of directories and concat them\n",
    "def loadDataFromFoldersOnList(foldersToLoad,inputFolders,fileType = \"\"):\n",
    "    clientList = []\n",
    "    print(len(foldersToLoad), \"datasets\")\n",
    "    for i in range(0,len(foldersToLoad)):\n",
    "        currentFolder = foldersToLoad[i]\n",
    "        print(i , \"-\", currentFolder,inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        #print(trainingDataSet[i])\n",
    "        temp_data = pd.read_csv(inputFolders+\"student_\"+currentFolder+\"_transformed\"+fileType+\".csv\")\n",
    "        print(\"Adding to the list: \", temp_data.shape)\n",
    "        clientList.append(temp_data)\n",
    "    # return the dataset        \n",
    "    return clientList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de574891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data\n",
      "8 datasets\n",
      "0 - rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw ../data_2019_processed/student_rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw_transformed.csv\n",
      "1 - RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI ../data_2019_processed/student_RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI_transformed.csv\n",
      "2 - VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is ../data_2019_processed/student_VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is_transformed.csv\n",
      "3 - Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw ../data_2019_processed/student_Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw_transformed.csv\n",
      "4 - XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA ../data_2019_processed/student_XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA_transformed.csv\n",
      "5 - YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw ../data_2019_processed/student_YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw_transformed.csv\n",
      "6 - ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM ../data_2019_processed/student_ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM_transformed.csv\n",
      "7 - ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY ../data_2019_processed/student_ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY_transformed.csv\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>sound</th>\n",
       "      <th>proximity</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>light</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678249</td>\n",
       "      <td>2018-05-14 16:16:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.211282e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678944</td>\n",
       "      <td>2018-05-14 16:17:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679639</td>\n",
       "      <td>2018-05-14 16:18:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680334</td>\n",
       "      <td>2018-05-14 16:19:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681028</td>\n",
       "      <td>2018-05-14 16:20:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819100e-03</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23751</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity  location     timestamp  time_to_next_alarm     sound  \\\n",
       "0          0.75       1.0  0.000000e+00            0.000000  0.515992   \n",
       "1          0.25       1.0  3.211282e-07            0.000000  0.542171   \n",
       "2          0.25       1.0  6.422564e-07            0.000000  0.515992   \n",
       "3          0.00       1.0  6.422564e-07            0.000000  0.515992   \n",
       "4          0.25       1.0  6.422564e-07            0.000000  0.531341   \n",
       "...         ...       ...           ...                 ...       ...   \n",
       "23747      0.25       1.0  5.819100e-03            0.000099  0.000000   \n",
       "23748      0.25       1.0  5.819743e-03            0.000694  0.000000   \n",
       "23749      0.25       1.0  5.819743e-03            0.000595  0.000000   \n",
       "23750      0.25       1.0  5.820064e-03            0.000595  0.000000   \n",
       "23751      0.50       1.0  5.820064e-03            0.000496  0.000000   \n",
       "\n",
       "       proximity  phone_lock     light  day_of_week  minutes_day  \\\n",
       "0            1.0         0.0  0.000000     1.000000     0.678249   \n",
       "1            0.0         1.0  0.000007     1.000000     0.678944   \n",
       "2            0.0         1.0  0.000000     1.000000     0.679639   \n",
       "3            0.0         1.0  0.000000     1.000000     0.680334   \n",
       "4            0.0         1.0  0.000000     1.000000     0.681028   \n",
       "...          ...         ...       ...          ...          ...   \n",
       "23747        1.0         1.0  0.000236     0.166667     0.510076   \n",
       "23748        1.0         1.0  0.000325     0.166667     0.512856   \n",
       "23749        1.0         1.0  0.000325     0.166667     0.513551   \n",
       "23750        1.0         1.0  0.000354     0.166667     0.513551   \n",
       "23751        0.0         1.0  0.000000     0.166667     0.514246   \n",
       "\n",
       "                  timestamp_text  class  \n",
       "0      2018-05-14 16:16:08+00:00  awake  \n",
       "1      2018-05-14 16:17:39+00:00  awake  \n",
       "2      2018-05-14 16:18:39+00:00  awake  \n",
       "3      2018-05-14 16:19:09+00:00  awake  \n",
       "4      2018-05-14 16:20:09+00:00  awake  \n",
       "...                          ...    ...  \n",
       "23747  2018-06-13 12:14:37+00:00  awake  \n",
       "23748  2018-06-13 12:18:08+00:00  awake  \n",
       "23749  2018-06-13 12:19:08+00:00  awake  \n",
       "23750  2018-06-13 12:19:38+00:00  awake  \n",
       "23751  2018-06-13 12:20:08+00:00  awake  \n",
       "\n",
       "[134888 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Preparing test data\")\n",
    " \n",
    "# test data comprising 25% of the data. It must be fixed to all models being evaluated\n",
    "#X_test  = pd.read_csv(inputFolders+\"test/allData-classification-numeric-normalized.csv\")\n",
    "X_test = loadDataFromFolders(testFolders,baseFolder,\"\")\n",
    "\n",
    "print()\n",
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44b239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing X_train data\n",
      "19 datasets\n",
      "0 - 0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs ../data_2019_processed/student_0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs_transformed_smote.csv\n",
      "Adding to the list:  (17993, 11)\n",
      "1 - 0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA ../data_2019_processed/student_0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA_transformed_smote.csv\n",
      "Adding to the list:  (11561, 11)\n",
      "2 - 2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0 ../data_2019_processed/student_2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0_transformed_smote.csv\n",
      "Adding to the list:  (3383, 11)\n",
      "3 - 2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys ../data_2019_processed/student_2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys_transformed_smote.csv\n",
      "Adding to the list:  (19389, 11)\n",
      "4 - 7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA ../data_2019_processed/student_7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA_transformed_smote.csv\n",
      "Adding to the list:  (2753, 11)\n",
      "5 - a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4 ../data_2019_processed/student_a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4_transformed_smote.csv\n",
      "Adding to the list:  (26567, 11)\n",
      "6 - ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc ../data_2019_processed/student_ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc_transformed_smote.csv\n",
      "Adding to the list:  (24534, 11)\n",
      "7 - Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U ../data_2019_processed/student_Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U_transformed_smote.csv\n",
      "Adding to the list:  (33903, 11)\n",
      "8 - CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA ../data_2019_processed/student_CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA_transformed_smote.csv\n",
      "Adding to the list:  (26440, 11)\n",
      "9 - DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc ../data_2019_processed/student_DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc_transformed_smote.csv\n",
      "Adding to the list:  (24484, 11)\n",
      "10 - dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY ../data_2019_processed/student_dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY_transformed_smote.csv\n",
      "Adding to the list:  (26020, 11)\n",
      "11 - HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo ../data_2019_processed/student_HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo_transformed_smote.csv\n",
      "Adding to the list:  (25932, 11)\n",
      "12 - jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw ../data_2019_processed/student_jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw_transformed_smote.csv\n",
      "Adding to the list:  (31873, 11)\n",
      "13 - JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I ../data_2019_processed/student_JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I_transformed_smote.csv\n",
      "Adding to the list:  (23244, 11)\n",
      "14 - K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8 ../data_2019_processed/student_K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8_transformed_smote.csv\n",
      "Adding to the list:  (19595, 11)\n",
      "15 - oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q ../data_2019_processed/student_oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q_transformed_smote.csv\n",
      "Adding to the list:  (21669, 11)\n",
      "16 - pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM ../data_2019_processed/student_pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM_transformed_smote.csv\n",
      "Adding to the list:  (33344, 11)\n",
      "17 - QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ ../data_2019_processed/student_QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ_transformed_smote.csv\n",
      "Adding to the list:  (22059, 11)\n",
      "18 - SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4 ../data_2019_processed/student_SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4_transformed_smote.csv\n",
      "Adding to the list:  (12709, 11)\n",
      "Total 19\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing X_train data\")\n",
    "# load cliend data\n",
    "clientList = loadDataFromFoldersOnList(trainFolders,baseFolder,\"_smote\")\n",
    "        \n",
    "print(\"Total\",(len(clientList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7fdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_to_next_alarm</th>\n",
       "      <th>sound</th>\n",
       "      <th>proximity</th>\n",
       "      <th>phone_lock</th>\n",
       "      <th>light</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>minutes_day</th>\n",
       "      <th>timestamp_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678249</td>\n",
       "      <td>2018-05-14 16:16:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.211282e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678944</td>\n",
       "      <td>2018-05-14 16:17:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679639</td>\n",
       "      <td>2018-05-14 16:18:39+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680334</td>\n",
       "      <td>2018-05-14 16:19:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422564e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681028</td>\n",
       "      <td>2018-05-14 16:20:09+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23747</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819100e-03</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.510076</td>\n",
       "      <td>2018-06-13 12:14:37+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23748</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.512856</td>\n",
       "      <td>2018-06-13 12:18:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23749</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.819743e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23750</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.513551</td>\n",
       "      <td>2018-06-13 12:19:38+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23751</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.820064e-03</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>2018-06-13 12:20:08+00:00</td>\n",
       "      <td>awake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity  location     timestamp  time_to_next_alarm     sound  \\\n",
       "0          0.75       1.0  0.000000e+00            0.000000  0.515992   \n",
       "1          0.25       1.0  3.211282e-07            0.000000  0.542171   \n",
       "2          0.25       1.0  6.422564e-07            0.000000  0.515992   \n",
       "3          0.00       1.0  6.422564e-07            0.000000  0.515992   \n",
       "4          0.25       1.0  6.422564e-07            0.000000  0.531341   \n",
       "...         ...       ...           ...                 ...       ...   \n",
       "23747      0.25       1.0  5.819100e-03            0.000099  0.000000   \n",
       "23748      0.25       1.0  5.819743e-03            0.000694  0.000000   \n",
       "23749      0.25       1.0  5.819743e-03            0.000595  0.000000   \n",
       "23750      0.25       1.0  5.820064e-03            0.000595  0.000000   \n",
       "23751      0.50       1.0  5.820064e-03            0.000496  0.000000   \n",
       "\n",
       "       proximity  phone_lock     light  day_of_week  minutes_day  \\\n",
       "0            1.0         0.0  0.000000     1.000000     0.678249   \n",
       "1            0.0         1.0  0.000007     1.000000     0.678944   \n",
       "2            0.0         1.0  0.000000     1.000000     0.679639   \n",
       "3            0.0         1.0  0.000000     1.000000     0.680334   \n",
       "4            0.0         1.0  0.000000     1.000000     0.681028   \n",
       "...          ...         ...       ...          ...          ...   \n",
       "23747        1.0         1.0  0.000236     0.166667     0.510076   \n",
       "23748        1.0         1.0  0.000325     0.166667     0.512856   \n",
       "23749        1.0         1.0  0.000325     0.166667     0.513551   \n",
       "23750        1.0         1.0  0.000354     0.166667     0.513551   \n",
       "23751        0.0         1.0  0.000000     0.166667     0.514246   \n",
       "\n",
       "                  timestamp_text  class  \n",
       "0      2018-05-14 16:16:08+00:00  awake  \n",
       "1      2018-05-14 16:17:39+00:00  awake  \n",
       "2      2018-05-14 16:18:39+00:00  awake  \n",
       "3      2018-05-14 16:19:09+00:00  awake  \n",
       "4      2018-05-14 16:20:09+00:00  awake  \n",
       "...                          ...    ...  \n",
       "23747  2018-06-13 12:14:37+00:00  awake  \n",
       "23748  2018-06-13 12:18:08+00:00  awake  \n",
       "23749  2018-06-13 12:19:08+00:00  awake  \n",
       "23750  2018-06-13 12:19:38+00:00  awake  \n",
       "23751  2018-06-13 12:20:08+00:00  awake  \n",
       "\n",
       "[134888 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undestand the dataset by looking on their infos\n",
    "print(X_test.info())\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7473fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# transform output to one_hot_encoding for the testing dataset\n",
    "X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "\n",
    "# transform output to one_hot_encoding for the input dataset\n",
    "for i in range(0,len(clientList)):\n",
    "    clientList[i] = transform_output_nominal_class_into_one_hot_encoding(clientList[i])\n",
    "    #print (clientList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float64\n",
      " 1   location            134888 non-null  float64\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float64\n",
      " 4   sound               134888 non-null  float64\n",
      " 5   proximity           134888 non-null  float64\n",
      " 6   phone_lock          134888 non-null  float64\n",
      " 7   light               134888 non-null  float64\n",
      " 8   day_of_week         134888 non-null  float64\n",
      " 9   minutes_day         134888 non-null  float64\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  uint8  \n",
      " 13  asleep              134888 non-null  uint8  \n",
      "dtypes: float64(10), object(2), uint8(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0830f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134888 entries, 0 to 23751\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   activity            134888 non-null  float32\n",
      " 1   location            134888 non-null  float32\n",
      " 2   timestamp           134888 non-null  float64\n",
      " 3   time_to_next_alarm  134888 non-null  float32\n",
      " 4   sound               134888 non-null  float32\n",
      " 5   proximity           134888 non-null  float32\n",
      " 6   phone_lock          134888 non-null  float32\n",
      " 7   light               134888 non-null  float32\n",
      " 8   day_of_week         134888 non-null  float32\n",
      " 9   minutes_day         134888 non-null  float32\n",
      " 10  timestamp_text      134888 non-null  object \n",
      " 11  class               134888 non-null  object \n",
      " 12  awake               134888 non-null  float32\n",
      " 13  asleep              134888 non-null  float32\n",
      "dtypes: float32(11), float64(1), object(2)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# transforms the data\n",
    "X_test = transform_data_type(X_test)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56557625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 15:45:41.628367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:41.654479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:41.654747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:41.655494: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-21 15:45:41.660663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:41.661000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:41.661254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:42.628892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:42.629239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:42.629255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-21 15:45:42.629511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-21 15:45:42.629561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3421 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selects the data to train and test\n",
    "X_test_data = X_test[inputFeatures]\n",
    "y_test_label = X_test[outputClasses]\n",
    "\n",
    "# transtorm data to tensor slices\n",
    "client_test_dataset = tf.data.Dataset.from_tensor_slices((X_test_data.values, y_test_label.values))\n",
    "\n",
    "#client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE, drop_remainder=True)\n",
    "client_test_dataset = client_test_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "\n",
    "print(client_test_dataset.element_spec)\n",
    "client_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021a0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_training_data = []\n",
    "# transform the data\n",
    "for i in range(0,len(clientList)):\n",
    "    # selects the data to train and test\n",
    "    data   = clientList[i][inputFeatures]\n",
    "    labels = clientList[i][outputClasses]\n",
    "    # transform the data to tensor slices\n",
    "    client_train_dataset = tf.data.Dataset.from_tensor_slices((data.values, labels.values))\n",
    "    # apply the configs\n",
    "    client_train_dataset = client_train_dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE)\n",
    "    # transform the data to\n",
    "    federated_training_data.append(client_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(16, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9357a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                160       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314\n",
      "Trainable params: 314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = create_keras_model()\n",
    "#keras_model.summary()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17708ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    #keras_model = create_keras_model()\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=client_train_dataset.element_spec,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), #BinaryCrossentropy\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58fa47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),#client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9279e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[9,16],\n",
      "      float32[16],\n",
      "      float32[16,8],\n",
      "      float32[8],\n",
      "      float32[8,2],\n",
      "      float32[2]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(fed_avg_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a32b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = fed_avg_process.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a74e0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Start timestamp: 1695307577.503 2023-09-21 15:46:17.503000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 15:46:24.454292: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  0, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8263231), ('loss', 0.40001583), ('num_examples', 407452), ('num_batches', 12745)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "\n",
      "awake\n",
      "Accuracy: 0.813660\n",
      "Precision: 0.813660\n",
      "Recall: 1.000000\n",
      "F1 score: 0.897258\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[     0  25135]\n",
      " [     0 109753]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.813660\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109753      0]\n",
      " [ 25135      0]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8136602218136528\n",
      "precision:  0.4068301109068264\n",
      "recall:  0.5\n",
      "f1_score:  0.4486288071091927\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n",
      "\n",
      "0 End timestamp: 1695307666.906343 2023-09-21 15:47:46.906343\n",
      "\n",
      "\n",
      "1 Start timestamp: 1695307667.411993 2023-09-21 15:47:47.411993\n",
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.83301103), ('loss', 0.36089352), ('num_examples', 407452), ('num_batches', 12745)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n",
      "\n",
      "awake\n",
      "Accuracy: 0.813660\n",
      "Precision: 0.813660\n",
      "Recall: 1.000000\n",
      "F1 score: 0.897258\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n",
      "[[     0  25135]\n",
      " [     0 109753]]\n",
      "\n",
      "asleep\n",
      "Accuracy: 0.813660\n",
      "Precision: 0.000000\n",
      "Recall: 0.000000\n",
      "F1 score: 0.000000\n",
      "Cohens kappa: 0.000000\n",
      "ROC AUC: 0.500000\n",
      "\\Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109753      0]\n",
      " [ 25135      0]]\n",
      "\n",
      "Global\n",
      "2\n",
      "accuracy:  0.8136602218136528\n",
      "precision:  0.4068301109068264\n",
      "recall:  0.5\n",
      "f1_score:  0.4486288071091927\n",
      "cohen_kappa_score:  0.0\n",
      "roc_auc_score:  0.5\n",
      "\n",
      "1 End timestamp: 1695307743.565354 2023-09-21 15:49:03.565354\n",
      "\n",
      "\n",
      "2 Start timestamp: 1695307744.065446 2023-09-21 15:49:04.065446\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.8477514), ('loss', 0.33324385), ('num_examples', 407452), ('num_batches', 12745)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m weights\u001b[38;5;241m.\u001b[39massign_weights_to(keras_model)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#tttt.model.assign_weights_to(keras_model)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m yhat_probs \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m yhat_probs_rounded \u001b[38;5;241m=\u001b[39m yhat_probs\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m     44\u001b[0m y_predited_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39myhat_probs_rounded,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mawake\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masleep\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2725\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2721\u001b[0m \u001b[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m   2722\u001b[0m \u001b[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m   2723\u001b[0m \u001b[38;5;66;03m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2725\u001b[0m   func_cache_key, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_cache_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2726\u001b[0m \u001b[43m      \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2728\u001b[0m   func_cache_key, _ \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_cache_key(\n\u001b[1;32m   2729\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_input_signature, captures)\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function_context.py:141\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    133\u001b[0m captures_dict_tracetype \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mfrom_object(\n\u001b[1;32m    134\u001b[0m     captures, signature_context)\n\u001b[1;32m    135\u001b[0m captures_signature \u001b[38;5;241m=\u001b[39m function_cache\u001b[38;5;241m.\u001b[39mCaptureSnapshot(\n\u001b[1;32m    136\u001b[0m     captures_dict_tracetype\u001b[38;5;241m.\u001b[39mmapping)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_cache\u001b[38;5;241m.\u001b[39mFunctionCacheKey(\n\u001b[1;32m    139\u001b[0m     args_signature,\n\u001b[1;32m    140\u001b[0m     captures_signature,\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mmake_function_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m), signature_context\u001b[38;5;241m.\u001b[39mdeletion_observer\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function_context.py:46\u001b[0m, in \u001b[0;36mmake_function_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m ctx \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Don't need to open an init_scope if the tf.function call is in eager mode\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# already.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m executing_eagerly \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m parent_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m xla_context_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/cpu-tensorflow-marcelo/nvidia-smi/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:986\u001b[0m, in \u001b[0;36mContext.executing_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecuting_eagerly\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread_local_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_eager\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roundData = []\n",
    "\n",
    "columns = ['NN_type','units','epochs','batch_size','max_iterations','Users','window_size','time_step',\n",
    "           'round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "           'TP','FP','FN','TN']\n",
    "\n",
    "USER_NUMBER = len(clientList)\n",
    "\n",
    "generalData = [NN_type,UNITS_NUMBER,NUM_EPOCHS,BATCH_SIZE,MAX_ITERATIONS,USER_NUMBER,TIME_SERIES_SIZE,TIME_STEP_SHIFT]\n",
    "\n",
    "for i in range(0,MAX_ITERATIONS):\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_stamp = current_time.timestamp()\n",
    "    print(i,\"Start timestamp:\", time_stamp,current_time)\n",
    "    \n",
    "    result = fed_avg_process.next(state, federated_training_data[0:19])\n",
    "    state = result.state\n",
    "    metrics = result.metrics\n",
    "    print('round  {}, metrics={}'.format(i,metrics))\n",
    "\n",
    "    print('')\n",
    "    #def keras_evaluate(state, round_num):\n",
    "        # Take our global model weights and push them back into a Keras model to\n",
    "        # use its standard `.evaluate()` method.\n",
    "    keras_model = create_keras_model()\n",
    "\n",
    "\n",
    "    keras_model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # get neural network weights\n",
    "    weights = fed_avg_process.get_model_weights(state)\n",
    "    weights.assign_weights_to(keras_model)\n",
    "\n",
    "\n",
    "    #tttt.model.assign_weights_to(keras_model)\n",
    "    yhat_probs = keras_model.predict(X_test_data,verbose=0)\n",
    "\n",
    "\n",
    "    yhat_probs_rounded = yhat_probs.round()\n",
    "\n",
    "    y_predited_df = pd.DataFrame(data=yhat_probs_rounded,columns=['awake','asleep']) \n",
    "    y_test_label_df = pd.DataFrame(data=y_test_label,columns=['awake','asleep']) \n",
    "    \n",
    "    # generate time metrics\n",
    "    current_time2 = datetime.datetime.now()\n",
    "    time_stamp2 = current_time2.timestamp()\n",
    "    processing_time_s = (time_stamp2-time_stamp)\n",
    "    # generate general metrics\n",
    "    rowData = [i,current_time,current_time2,processing_time_s,(processing_time_s)/60]\n",
    "\n",
    "    print('')\n",
    "    print('awake')    \n",
    "    res,resA = printMetrics(y_test_label_df['awake'],y_predited_df['awake'])\n",
    "    metricsFromOneRound = list()\n",
    "    metricsFromOneRound.append(res)\n",
    "   \n",
    "    #columns = ['NN_type','units','epochs','batch_size','max_iterations',''Users',\n",
    "    #            round_iteration','start_time','end_time','round_time_s','round_time_m',\n",
    "    #           'class','accuracy','precision','recall','f1_score','cohen_kappa_score','roc_auc_score','confusion_matrix',\n",
    "    #           'TP','FP','FN','TN']\n",
    "    # new data\n",
    "    classData = np.concatenate((['awake'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    \n",
    "    print('')\n",
    "    print('asleep')\n",
    "    res,resA = printMetrics(y_test_label_df['asleep'],y_predited_df['asleep'])\n",
    "    metricsFromOneRound.append(res)\n",
    "    # new data\n",
    "    classData = np.concatenate((['asleep'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print('Global')\n",
    "    resA = showGlobalMetrics(metricsFromOneRound) #return [accuracy,precision,recall,f1_score,cohen_kappa_score,roc_auc_score\n",
    "    # new data\n",
    "    classData = np.concatenate((['avg'], resA))\n",
    "    classData = np.concatenate((rowData, classData))\n",
    "    classData = np.concatenate((generalData, classData))\n",
    "    roundData.append(classData)\n",
    "    print('')\n",
    "    print(i,\"End timestamp:\", time_stamp2,current_time2)\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMetrics = pd.DataFrame(data=roundData,columns=columns) \n",
    "\n",
    "dataMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataMetrics.to_csv(outputMetricFile, sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
